\chapter{Introduction and Overview}

Most existing Unmanned Aerial Systems (UASs) require two or more human operators~\cite{GoodrichMorse2008,MurphyStoverPrattGriffin2006}. Standard UAS practice is to have one human to control the aerial vehicle and another to control the camera or other payloads. In addition to this a third human is often responsible for overseeing task completion and interfacing with the command structure. Although some argue persuasively that this is a desirable organization~\cite{MurphyBurke2010}, there is considerable interest in reducing the required number of humans and reducing human workload using improved autonomy and enhanced user interfaces~\cite{Cummings2007,MitchellCummings2005,goodrich2010fanout}.

UAV enabled wilderness search and rescue (WiSAR) has been a focus of the Human
Centered Machine Intelligence (HCMI), Multiple Agent Intelligent Coordination and Control (MAGICC) and Computer Vision (CV) labs at Brigham Young University since 2005.  In that time research has been conducted on human interaction with miniature unmanned aerial vehicles (mUAVs), improving target detection by enhancing video taken from a mUAV, integrating mUAVs into a search and rescue environment, and improving the mUAVs chance of getting video footage of the target.   

The research results over this time period appear promising ~\cite{cluff2009unified,cooper2007supporting,engh2008see,humphrey2009information,lin2010supporting,morse2008application,morse2010color,rasmussen2008enhancement}, however, it remains unknown how these improvements will effect human workload within the context of a UAS.  While it was possible to make changes to our existing WiSAR UAS and then perform user studies to view the effects of these changes, we felt that the more important scientific problem lay in discovering a way to measure changes in human workload as a result of changes to a UAS.  To accomplish this we chose to use system modeling. 

\begin{comment}
Lacking a fully operational UAS to experiment with, the question became how can we measure the human workload effects of introducing changes into a UAS without a working UAS?  And can we use these results acorssAlso, we desired a solution that was not limited to a single UAS but a solution that could be applied to any UAS.  The solution we came up with was

Lacking the resources to create a fully operational UAS, the question became how can we measure the effects of introducing new research into a UAS?  In response to this question we chose to use system modeling. 

their own context it is unknown how effective they are within the context of a real UAS.  prototypes of almost all the functionality existed, there was no way of knowing that the system as a whole would meet the requirements.  Instead of blindly pressing forward with the software development we decided that the more important scientific problem was to figure out how to model and validate the system design before implementation.
\end{comment}

System modeling is not a new approach, though applying system modeling to human-machine systems requires extending most modeling languages.  There are many different modeling languages, each of which is designed to perform specific types of validation~\cite{bolton2013litreview}.  For example, Brahms focuses on performing agent-based simulations, EOFM focuses on task analytics, and ACT-R focuses on human cognition.  Due to the complexity of these modeling languages and our need to manipulate the internal workings of the language we decided that our shortest path forward was to create our own simple modeling framework.  We call this modeling framework the Model Abstraction Framework.

\begin{comment}
In order to obtain workload metrics from a modeling language we knew that we would need to manipulate the input language, the model checker, the simulator, etc. of said modeling language.  We determined that the shortest path

 the ability to manipulate all aspects of the modelingEach of these modeling languages has proven successful at modeling human-machine systems, however, at the time none offered the tools necessary to extract the workload data we desired.  We determined the fastest approach for acheiving   it was possible to attempt to add our workload metrics to one of the existing modeling languages capable of modeling a UAS, such as Brahms~\cite{}, EOFM~\cite{}, ACT-R~\cite{}, etc.
Finally, we desired to perform human workload measurements on the model as part of our approach to reducing the required number of humans involved in UASs.
\end{comment}

The Model Abstraction Framework consists of the following core components:  Models, Model Parser, Modeling Interface, Simulator, and Workload Viewer.  A link to the source code is found in appendix~\ref{code}.  The Model Abstraction Framework uses XML as the primary modeling language.  The models consist of a set of Directed Role Graphs (DiRGs) representing the entities which are performing actions, and a Directed Team Graph (DiTG) representing the communication network between the different entities.  The model is then parsed using the Model Parser.  The Model Parser checks that the model syntax is correct and converts the XML into a set of Java classes that implement the Modeling Interface, a set of Java interfaces and abstract classes.  The Modeling Interface allows the model to be expressed as a labeled state transition system to be run by the Simulator.  The Simulator is a core set of Java classes which simulates the running of the model and gathers workload metrics.  The simulation can be performed as a stand-alone application or it can be run inside of Java Pathfinder (JPF) to perform model checking.  The workload viewer allows us to view human workload measures in real-time when the simulation is run as a stand-alone application.

We present two workload measurements, {\em Resource Workload Metric} and {\em Decision Workload Metric}, based off of multiple resource theory~\cite{wickens2002multiple} with ties to queuing theory~\cite{newell1994unified} and operator fan-out theory~\cite{goodrich2010fanout}.  By relating these theories to the different operational components of the model we obtain a quantitative measure of a human's workload for each time-step in the system.  Additionally we adapt the Wickens' computational model~\cite{wickens2002multiple} to the Model Abstraction Framework in an attempt to see how and where this metric differs from our own.

We perform a case study representing the introduction of a UAS into the National Air Space.  We chose to model a UAS operating within the National Air Space for three reasons: {\em a)} it is similar to the work done in WiSAR, {\em b)} the goals outlined by the FAA are similar to our own~\cite{nasroadmap}, and {\em c)} the lack of modeling information, requiring the use of high levels of abstraction.  As part of the case study we created four variations of the model to see how the workload metrics varied between models.

The verification of the metrics in this thesis is done using a {\em consistency} approach.  Using known high and low workload scenarios obtained from WiSAR~\cite{Adams2009Cognitive}, we check that the workload is consistent with our expected results.  While these results are inconslusive regarding actual human workload, we were pleased to find that the workload measures are consistent with known high workload scenarios.  We were also pleased that our workload metric, while more expressive, was consistent with the Adapted Wickens' Model.

\begin{comment}
   Known high and low workload scenarios, similar to those in WiSAR, are placed in the model.  Workload is consistent if it rises and falls as expected given known scenarios, and a {\em sensitivity}We were very pleased with the results of this case study.  Firstly because the Model Abstraction Framework proved capable of expressing our highly abstracted model.  Second, by using a {\em consistency}

using the Workload Viewer we were able to show that the Model Abstraction Framework is capable of expressing a UAS using high levels of abstraction.  The results of   They also demonstrate the ability to model systems using varying degrees of abstraction.  The verification of the metrics in this thesis is done by a {\em consistency} approach, showing that workload rises and falls as expected given known difficult and easy scenarios, respectively.  Future work will provide a more detailed verification.
\end{comment}

\section{Overview and Papers}

Chapter \ref{ch:paper1} consists of a paper published in the IEEE International Conference on Systems, Man, and Cybernetics, Manchester, England, 2013. It presents our core conceptual model, details of the Model Abstraction Framework, and a WiSAR model implemented in Java.  It also presents how the Simulator is able to validate the model using JPF.

Chapter \ref{ch:example} presents an example scenario along with a summary of the concepts that facilitate the collection of metric data.
\begin{comment}
Chapter 3 presents an extension of our conceptual model in the form of the DiTG.  It also presents a formal taxonomy of workload metrics and how that taxonomy applies to our conceptual model.  Lastly it reports the results of adding the workload metrics into the simulation framework.  Much of the work performed for this paper was completed by others; it has been added to this thesis for completeness.


Chapter 4 presents an XML Model Extension for the Model Abstraction Framework which makes it easier for the modeler to create a labeled state transition system and reduces the likelihood of coding errors in the resulting Java implementation of that system.
\end{comment}

Chapter \ref{ch:workload} presents our baseline workload metric, which is an adaptation of the Wickens' computational model for calculating cognitive resource load~\cite{wickens2002multiple}.  It then presents two new workload metrics, the{\em Resource Workload Metric} and the {\em Decision Workload Metric}.

Chapter \ref{ch:UASinNAS} presents a case study which involves modeling the integration of a UAS into the NAS.  It describes the model scenario, four model variations, and provides a detailed analysis and comparison of the results generated by these models.

Chapter \ref{ch:relatedwork} describes the similarities and differences with other work that is closely related to our approach of measuring human workload and modeling human-machine systems.

Chapter \ref{ch:summary} contains a summary of the work, threats to validity, and future work needed to accomplish our goals.

\begin{comment}
The appendices include the initial WiSAR proposal, the core modeling framework classes, an XML model, and simulation logs.
\end{comment}